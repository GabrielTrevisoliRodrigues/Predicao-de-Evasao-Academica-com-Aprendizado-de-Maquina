# ğŸ“ PrediÃ§Ã£o de EvasÃ£o AcadÃªmica com Aprendizado de MÃ¡quina

Este projeto apresenta um **pipeline completo de Machine Learning** aplicado ao problema de **evasÃ£o acadÃªmica**, utilizando dados socioeconÃ´micos e de desempenho acadÃªmico de estudantes.

O objetivo central Ã© **identificar antecipadamente alunos com maior risco de evasÃ£o**, permitindo que instituiÃ§Ãµes de ensino adotem **aÃ§Ãµes preventivas** baseadas em dados.

---

## ğŸ¯ Objetivo do Projeto

- Analisar e compreender o comportamento dos dados educacionais
- Selecionar variÃ¡veis relevantes com base em anÃ¡lise estatÃ­stica
- Construir e comparar modelos de classificaÃ§Ã£o supervisionada
- Otimizar e avaliar o modelo final
- Interpretar os resultados de forma aplicada ao contexto educacional

---

## ğŸ“Š Etapa 1 â€” AnÃ¡lise ExploratÃ³ria dos Dados (EDA)

Durante a EDA, observou-se que:

- Todas as variÃ¡veis sÃ£o numÃ©ricas, exceto a variÃ¡vel alvo (*evasÃ£o*)
- NÃ£o existem valores faltantes nem duplicados
- O dataset original possui **36 features**

### ğŸ” AnÃ¡lises realizadas
- **AnÃ¡lise univariada**: estudo de simetria e assimetria das distribuiÃ§Ãµes
- **AnÃ¡lise bivariada**:
  - CorrelaÃ§Ã£o entre variÃ¡veis para evitar redundÃ¢ncias
  - CorrelaÃ§Ã£o ponto-bisserial entre cada feature e o target

Com base nessas anÃ¡lises, foram selecionadas **13 variÃ¡veis mais relevantes** para a modelagem.

---

## âš™ï¸ Etapa 2 â€” PrÃ©-processamento

Para as 13 features selecionadas, foram aplicadas as seguintes etapas:

1. **PowerTransformer** para reduzir a assimetria das distribuiÃ§Ãµes
2. **StandardScaler** para padronizaÃ§Ã£o (mÃ©dia zero e desvio padrÃ£o igual a 1)
3. DivisÃ£o do dataset em **conjuntos de treino e teste**

---

## ğŸ¤– Etapa 3 â€” Modelagem

Foram treinados e avaliados quatro modelos de classificaÃ§Ã£o:

| Modelo | DescriÃ§Ã£o |
|------|-----------|
| Logistic Regression | Modelo linear utilizado como baseline |
| KNN (K-Nearest Neighbors) | ClassificaÃ§Ã£o baseada em proximidade |
| Random Forest | Ensemble de Ã¡rvores para reduÃ§Ã£o de variÃ¢ncia |
| Gradient Boosting | Modelo baseado em boosting de classificadores fracos |

---

## ğŸ“ˆ Etapa 4 â€” AvaliaÃ§Ã£o dos Modelos

As mÃ©tricas utilizadas foram:

- Accuracy  
- Precision  
- Recall  
- F1-score  

### ğŸ¯ ImportÃ¢ncia do Recall
No contexto da evasÃ£o acadÃªmica, **minimizar falsos negativos** Ã© fundamental â€” ou seja, evitar que alunos em risco nÃ£o sejam identificados pelo modelo.  
Por isso, o **Recall** foi adotado como mÃ©trica principal de avaliaÃ§Ã£o.

### ğŸ§¾ Resultados
Todos os modelos apresentaram desempenho consistente, com mÃ©tricas variando entre **0.86 e 0.89**.  
O **Gradient Boosting Classifier** apresentou desempenho ligeiramente superior e foi selecionado para a etapa de otimizaÃ§Ã£o.

---

## ğŸ”§ Etapa 5 â€” OtimizaÃ§Ã£o e InterpretaÃ§Ã£o

Foi aplicado **GridSearchCV** ao modelo de Gradient Boosting para ajuste de hiperparÃ¢metros.  
A otimizaÃ§Ã£o nÃ£o resultou em ganhos significativos, indicando que o modelo inicial jÃ¡ estava bem ajustado.

Mesmo assim, o Gradient Boosting foi mantido como **modelo final**, apresentando o melhor equilÃ­brio entre recall e desempenho geral.

O projeto tambÃ©m contempla anÃ¡lise de **interpretabilidade**, reforÃ§ando a transparÃªncia das decisÃµes do modelo.

---

## ğŸ“‚ Estrutura do Projeto

```text
â”œâ”€â”€ Dia 1 - EDA inicial.ipynb
â”œâ”€â”€ Dia 2 - EDA e PrÃ©-processamento.ipynb
â”œâ”€â”€ Dia 3 - Modelagem e Baseline.ipynb
â”œâ”€â”€ Dia 4 â€“ OtimizaÃ§Ã£o e InterpretaÃ§Ã£o.ipynb
â”œâ”€â”€ avaliacao_gradient_boosting.json

