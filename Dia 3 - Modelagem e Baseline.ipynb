{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf63a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n",
      "Tamanho de treino: (3539, 13) | Tamanho de teste: (885, 13)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR BIBLIOTECAS E CARREGAR DADOS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "#para ignorar um futurewarning por questão estética\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Carregar os dados\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "print(\"Dados carregados com sucesso!\")\n",
    "print(\"Tamanho de treino:\", X_train.shape, \"| Tamanho de teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52855114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIAR UMA FUNÇÃO PARA TREINAR E AVALIAR OS MODELOS\n",
    "\n",
    "def avaliar_modelo(modelo, X_train, X_test, y_train, y_test):\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"=== {modelo.__class__.__name__} ===\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(\"\\nMatriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return {\n",
    "        'Modelo': modelo.__class__.__name__,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-score': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716c673",
   "metadata": {},
   "source": [
    "DEFINIÇÃO DOS HIPER-PARAMETROS USADOS A BAIXO:\n",
    "Os modelos foram instanciados com os hiperparâmetros mostrados no código-fonte do experimento, sem uso de busca automatizada de hiperparâmetros. As instâncias utilizadas foram: LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors=5), RandomForestClassifier(n_estimators=100, random_state=42) e GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42). Parâmetros não explicitados no código permaneceram com os valores padrão da biblioteca scikit-learn (por exemplo, solver='lbfgs' em LogisticRegression, criterion='gini' e max_depth=None em RandomForestClassifier, e profundidade de árvore max_depth=3 em GradientBoostingClassifier).\n",
    "\n",
    "A escolha dessas configurações foi deliberada e guiada por princípios metodológicos: (i) simplicidade e reprodutibilidade — usar configurações padrão reduz o número de variáveis experimentais e facilita a reprodutibilidade; (ii) trade-off bias/variance — valores como n_estimators=100 para ensembles (Random Forest e Gradient Boosting) fornecem robustez e redução de variância sem custo computacional excessivo; (iii) robustez em dados tabulares — k=5 no KNN é um compromisso clássico entre sensibilidade a ruído e preservação de fronteiras de decisão; (iv) garantir convergência numérica — max_iter=1000 na regressão logística previne término prematuro do otimizador em presença de variáveis correlacionadas. Essas decisões foram validadas empiricamente por execuções exploratórias locais, priorizando interpretações estáveis das métricas (precision, recall, F1) em vez de otimização exaustiva.\n",
    "\n",
    "\n",
    "Observação: Após a aplicação e avaliação inicial dos modelos, aquele que apresentar o melhor desempenho será selecionado para um processo de otimização utilizando o método GridSearchCV no notebook do dia 4. Essa estratégia busca equilibrar a qualidade do ajuste com a eficiência computacional, uma vez que o GridSearch demanda alto custo de processamento. Assim, a busca exaustiva por hiperparâmetros será restrita apenas ao modelo com maior potencial de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40678538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogisticRegression ===\n",
      "Accuracy:  0.8734\n",
      "Precision: 0.8726\n",
      "Recall:    0.8734\n",
      "F1-score:  0.8702\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[568  33]\n",
      " [ 79 205]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       601\n",
      "           1       0.86      0.72      0.79       284\n",
      "\n",
      "    accuracy                           0.87       885\n",
      "   macro avg       0.87      0.83      0.85       885\n",
      "weighted avg       0.87      0.87      0.87       885\n",
      "\n",
      "--------------------------------------------------\n",
      "=== KNeighborsClassifier ===\n",
      "Accuracy:  0.8486\n",
      "Precision: 0.8478\n",
      "Recall:    0.8486\n",
      "F1-score:  0.8428\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[566  35]\n",
      " [ 99 185]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       601\n",
      "           1       0.84      0.65      0.73       284\n",
      "\n",
      "    accuracy                           0.85       885\n",
      "   macro avg       0.85      0.80      0.81       885\n",
      "weighted avg       0.85      0.85      0.84       885\n",
      "\n",
      "--------------------------------------------------\n",
      "=== RandomForestClassifier ===\n",
      "Accuracy:  0.8633\n",
      "Precision: 0.8615\n",
      "Recall:    0.8633\n",
      "F1-score:  0.8602\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[561  40]\n",
      " [ 81 203]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       601\n",
      "           1       0.84      0.71      0.77       284\n",
      "\n",
      "    accuracy                           0.86       885\n",
      "   macro avg       0.85      0.82      0.84       885\n",
      "weighted avg       0.86      0.86      0.86       885\n",
      "\n",
      "--------------------------------------------------\n",
      "=== GradientBoostingClassifier ===\n",
      "Accuracy:  0.8814\n",
      "Precision: 0.8801\n",
      "Recall:    0.8814\n",
      "F1-score:  0.8793\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[565  36]\n",
      " [ 69 215]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       601\n",
      "           1       0.86      0.76      0.80       284\n",
      "\n",
      "    accuracy                           0.88       885\n",
      "   macro avg       0.87      0.85      0.86       885\n",
      "weighted avg       0.88      0.88      0.88       885\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# EFETIVAMENTE TREINAR E AVALIAR OS 4 MODELOS\n",
    "\n",
    "resultados = []\n",
    "\n",
    "# 1. Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "resultados.append(avaliar_modelo(log_reg, X_train, X_test, y_train, y_test))\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "resultados.append(avaliar_modelo(knn, X_train, X_test, y_train, y_test))\n",
    "\n",
    "# 3. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "resultados.append(avaliar_modelo(rf, X_train, X_test, y_train, y_test))\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "resultados.append(avaliar_modelo(gb, X_train, X_test, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456c880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.880066</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.879282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.873446</td>\n",
       "      <td>0.872586</td>\n",
       "      <td>0.873446</td>\n",
       "      <td>0.870203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>0.861496</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>0.860213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.848588</td>\n",
       "      <td>0.847849</td>\n",
       "      <td>0.848588</td>\n",
       "      <td>0.842801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Modelo  Accuracy  Precision    Recall  F1-score\n",
       "3  GradientBoostingClassifier  0.881356   0.880066  0.881356  0.879282\n",
       "0          LogisticRegression  0.873446   0.872586  0.873446  0.870203\n",
       "2      RandomForestClassifier  0.863277   0.861496  0.863277  0.860213\n",
       "1        KNeighborsClassifier  0.848588   0.847849  0.848588  0.842801"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COMPARAR OS RESULTADOS DE FORMA ORGANIZADA EM UMA TABELA\n",
    "\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "resultados_df = resultados_df.sort_values(by=\"Recall\", ascending=False)\n",
    "display(resultados_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "431b1cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Modelo selecionado para otimização ===\n",
      "Modelo escolhido: GradientBoostingClassifier\n",
      "Recall: 0.881\n",
      "F1-score: 0.879\n",
      "\n",
      "✅ Modelo Gradient Boosting definido como modelo final para otimização.\n"
     ]
    }
   ],
   "source": [
    "# ESCOLHA E JUSTIFICATIVA DO MODELO FINAL\n",
    "\n",
    "# Identificar o melhor modelo com base no Recall e F1-score\n",
    "melhor_modelo = resultados_df.sort_values(by=[\"Recall\", \"F1-score\"], ascending=False).iloc[0]\n",
    "modelo_escolhido = melhor_modelo[\"Modelo\"]\n",
    "\n",
    "print(\"=== Modelo selecionado para otimização ===\")\n",
    "print(f\"Modelo escolhido: {modelo_escolhido}\")\n",
    "print(f\"Recall: {melhor_modelo['Recall']:.3f}\")\n",
    "print(f\"F1-score: {melhor_modelo['F1-score']:.3f}\\n\")\n",
    "\n",
    "# Definir o modelo final para as próximas análises\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "modelo_final = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Modelo Gradient Boosting definido como modelo final para otimização.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddbfc1",
   "metadata": {},
   "source": [
    "JUSTIFICATIVA ESCOLHA DE MODELO PARA OTIMIZAÇÃO NO DIA 4\n",
    "\n",
    "O modelo escolhido foi o Gradient Boosting Classifier, pois apresentou o melhor equilíbrio entre Recall e F1-score.\n",
    "No contexto do problema de evasão acadêmica, o Recall é uma métrica crucial, já que representa a capacidade do modelo\n",
    "de identificar corretamente os alunos que estão em risco de evadir. \n",
    "\n",
    "Embora outros modelos tenham apresentado resultados próximos, o Gradient Boosting demonstrou desempenho consistente\n",
    "e boa capacidade de generalização, sendo uma excelente escolha para a etapa de otimização de hiperparâmetros\n",
    "que será realizada no Dia 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03baa5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparação treino vs teste ===\n",
      "Treino → Accuracy: 0.877, Recall: 0.877, F1: 0.875\n",
      "Teste  → Accuracy: 0.881, Recall: 0.881, F1: 0.879\n",
      "\n",
      "✅ O modelo generaliza bem — não há sinais fortes de overfitting.\n"
     ]
    }
   ],
   "source": [
    "# NESSA E NA CELULA ABAIXO ANALISAMOS SE HOUVE OVERFITTING NO MODELO GRADIENT BOOSTING\n",
    "\n",
    "# AVALIAÇÃO DE OVERFITTING: COMPARAÇÃO TREINO VS TESTE \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Treinar o modelo final no conjunto de treino\n",
    "modelo_final.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no treino e no teste\n",
    "y_pred_train = modelo_final.predict(X_train)\n",
    "y_pred_test = modelo_final.predict(X_test)\n",
    "\n",
    "# Função para calcular métricas\n",
    "def calc_metricas(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'F1-score': f1_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "# Calcular métricas para treino e teste\n",
    "metricas_train = calc_metricas(y_train, y_pred_train)\n",
    "metricas_test = calc_metricas(y_test, y_pred_test)\n",
    "\n",
    "# Exibir comparação\n",
    "print(\"=== Comparação treino vs teste ===\")\n",
    "print(f\"Treino → Accuracy: {metricas_train['Accuracy']:.3f}, Recall: {metricas_train['Recall']:.3f}, F1: {metricas_train['F1-score']:.3f}\")\n",
    "print(f\"Teste  → Accuracy: {metricas_test['Accuracy']:.3f}, Recall: {metricas_test['Recall']:.3f}, F1: {metricas_test['F1-score']:.3f}\")\n",
    "\n",
    "# Análise automática\n",
    "dif_recall = metricas_train['Recall'] - metricas_test['Recall']\n",
    "dif_f1 = metricas_train['F1-score'] - metricas_test['F1-score']\n",
    "\n",
    "if dif_recall > 0.05 or dif_f1 > 0.05:\n",
    "    print(\"\\n⚠️ Há indícios de overfitting: o modelo performa significativamente melhor no treino do que no teste.\")\n",
    "else:\n",
    "    print(\"\\n✅ O modelo generaliza bem — não há sinais fortes de overfitting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189a0725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Validação cruzada (5 folds) ===\n",
      "Recall por fold: [0.856 0.857 0.87  0.843 0.87 ]\n",
      "Recall médio: 0.859 ± 0.010\n",
      "F1 por fold: [0.853 0.855 0.867 0.841 0.866]\n",
      "F1 médio: 0.857 ± 0.010\n",
      "\n",
      "✅ O desempenho é estável entre os folds — o modelo é consistente.\n"
     ]
    }
   ],
   "source": [
    "# NESSA CELULA ANALISAMOS SE HOUVE OVERFITTING NO MODELO GRADIENT BOOSTING\n",
    "\n",
    "# AVALIAÇÃO DE OVERFITTING: VALIDAÇÃO CRUZADA PARA CONFIRMAR ESTABILIDADE DO MODELO\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Executar validação cruzada no conjunto de treino\n",
    "scores_recall = cross_val_score(modelo_final, X_train, y_train, cv=5, scoring='recall_weighted')\n",
    "scores_f1 = cross_val_score(modelo_final, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"=== Validação cruzada (5 folds) ===\")\n",
    "print(f\"Recall por fold: {np.round(scores_recall, 3)}\")\n",
    "print(f\"Recall médio: {scores_recall.mean():.3f} ± {scores_recall.std():.3f}\")\n",
    "print(f\"F1 por fold: {np.round(scores_f1, 3)}\")\n",
    "print(f\"F1 médio: {scores_f1.mean():.3f} ± {scores_f1.std():.3f}\")\n",
    "\n",
    "# Análise automática\n",
    "if scores_f1.std() < 0.02:\n",
    "    print(\"\\n✅ O desempenho é estável entre os folds — o modelo é consistente.\")\n",
    "elif scores_f1.std() < 0.05:\n",
    "    print(\"\\n⚠️ Pequena variação entre folds — desempenho razoavelmente estável.\")\n",
    "else:\n",
    "    print(\"\\n❗ Alta variação entre folds — possível instabilidade ou overfitting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237c9af",
   "metadata": {},
   "source": [
    "AMBAS AS AVALIAÇÃOES DE OVERFITTING FORAM SATISFATÓRIAS \n",
    "................................................................................................................................................................................................................................................................"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f02aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Avaliação salva em 'avaliacao_gradient_boosting.json'\n"
     ]
    }
   ],
   "source": [
    "# SALVANDO A AVALIAÇÃO DO MODELO ESCOLHIDO EM UM JSON\n",
    "\n",
    "import json\n",
    "\n",
    "avaliacao = {\n",
    "    \"Treino_vs_Teste\": {\"Train\": metricas_train, \"Test\": metricas_test},\n",
    "    \"CrossValidation\": {\n",
    "        \"Recall_medio\": scores_recall.mean(),\n",
    "        \"Recall_std\": scores_recall.std(),\n",
    "        \"F1_medio\": scores_f1.mean(),\n",
    "        \"F1_std\": scores_f1.std()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"avaliacao_gradient_boosting.json\", \"w\") as f:\n",
    "    json.dump(avaliacao, f, indent=4)\n",
    "\n",
    "print(\"✅ Avaliação salva em 'avaliacao_gradient_boosting.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7917f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados salvos em 'resultados_modelagem.csv'.\n"
     ]
    }
   ],
   "source": [
    "# SALVANDO OS RESULTADOS EM UM ARQUIVO .csv\n",
    "\n",
    "resultados_df.to_csv(\"resultados_modelagem.csv\", index=False)\n",
    "print(\"Resultados salvos em 'resultados_modelagem.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
