{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00d7e00",
   "metadata": {},
   "source": [
    "Usaremos o GridSearch para tentar otimizar o modelo que obteve melhores resultados no dia 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIA 4 - OTIMIZAÇÃO E INTERPRETAÇÃO\n",
    "\n",
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib  # para salvar o modelo treinado\n",
    "\n",
    "# Carregar dados salvos no Dia 2\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "print(\"✅ Dados carregados com sucesso!\")\n",
    "print(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20911d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo base e grade de hiperparâmetros \n",
    "\n",
    "modelo_base = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Grade de parâmetros para busca\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(\"Grade de parâmetros definida.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202df648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimização com GridSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall_weighted',  # métrica principal: recall\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Busca concluída!\")\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo otimizado\n",
    "\n",
    "melhor_modelo = grid_search.best_estimator_\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "y_pred = melhor_modelo.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"=== Desempenho do modelo otimizado ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5748c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das variáveis (feature importance)\n",
    "\n",
    "importances = melhor_modelo.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Ordenar pela importância\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_features = features[indices]\n",
    "sorted_importances = importances[indices]\n",
    "\n",
    "# Exibir as 10 mais relevantes\n",
    "top_n = 10\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=sorted_importances[:top_n], y=sorted_features[:top_n], palette=\"viridis\")\n",
    "plt.title(\"Top 10 Variáveis Mais Importantes - Gradient Boosting\")\n",
    "plt.xlabel(\"Importância\")\n",
    "plt.ylabel(\"Variável\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e916add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo otimizado\n",
    "\n",
    "joblib.dump(melhor_modelo, \"modelo_gradient_boosting_otimizado.pkl\")\n",
    "print(\"✅ Modelo otimizado salvo como 'modelo_gradient_boosting_otimizado.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130e5dd",
   "metadata": {},
   "source": [
    "CONCLUSÃO: O GridSearch não obteve resultados que otimizassem o Gradient Boosting. Entretanto, este algoritmo continua sendo o melhor para a analise preditiva de evasão academica, tendo em vista os resultados e justificativas ressaltadas no notebook do dia 3.\n",
    "Portanto, este trabalho é concluido provando a eficacia do Gradient Boosting para a previsão de evasão academica em relação aos outros modelos de aprendizado usados. Para além disso, todos os modelos obtiveram bom resultados em torno de 0.88 nas metricas de avaliação de resultados "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
